{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5c948c3-a196-458a-a7df-79ad3d1743f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/doreenquisido/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/doreenquisido/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/doreenquisido/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88b96b1c-02af-46a3-bc65-7f7e8c7f641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>plot two teen couples go church party drink dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>happy bastard 's quick movie review damn y2k b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>movies like make jaded movie viewer thankful i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>`` quest camelot `` warner bros first feature-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>synopsis mentally unstable man undergoing psyc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_review  \\\n",
       "0  plot : two teen couples go to a church party ,...   \n",
       "1  the happy bastard's quick movie review \\ndamn ...   \n",
       "2  it is movies like these that make a jaded movi...   \n",
       "3   \" quest for camelot \" is warner bros . ' firs...   \n",
       "4  synopsis : a mentally unstable man undergoing ...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  plot two teen couples go church party drink dr...  \n",
       "1  happy bastard 's quick movie review damn y2k b...  \n",
       "2  movies like make jaded movie viewer thankful i...  \n",
       "3  `` quest camelot `` warner bros first feature-...  \n",
       "4  synopsis mentally unstable man undergoing psyc...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2: Load and Preprocess Data\n",
    "\n",
    "# 1. Load the IMDB Movie Reviews dataset\n",
    "documents = []\n",
    "for fileid in movie_reviews.fileids():\n",
    "    review_text = movie_reviews.raw(fileid)\n",
    "    documents.append(review_text)\n",
    "\n",
    "# 2. Preprocess Text\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct = set(string.punctuation)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove punctuation and stopwords\n",
    "    cleaned_tokens = [\n",
    "        word for word in tokens \n",
    "        if word not in punct and word not in stop_words\n",
    "    ]\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "cleaned_reviews = [preprocess_text(review) for review in documents]\n",
    "\n",
    "# 3. Store cleaned text in a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"original_review\": documents,\n",
    "    \"cleaned_review\": cleaned_reviews\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6461ffb-1d05-44fa-9261-11ed5e688e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features Created\n",
      "Shape of the feature matrix (X): (2000, 5000)\n",
      "This means we have 2000 reviews and 5000 unique features/words.\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Convert Text to Numerical Features\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit the vectorizer to the cleaned reviews and transform the data\n",
    "X = tfidf_vectorizer.fit_transform(df['cleaned_review'])\n",
    "\n",
    "print(\"Numerical Features Created\")\n",
    "print(f\"Shape of the feature matrix (X): {X.shape}\")\n",
    "print(f\"This means we have {X.shape[0]} reviews and {X.shape[1]} unique features/words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bb0cb87-881f-43f5-a976-322ecde79b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Clustering Results\n",
      "                                      cleaned_review  kmeans_cluster\n",
      "0  plot two teen couples go church party drink dr...               2\n",
      "1  happy bastard 's quick movie review damn y2k b...               1\n",
      "2  movies like make jaded movie viewer thankful i...               2\n",
      "3  `` quest camelot `` warner bros first feature-...               3\n",
      "4  synopsis mentally unstable man undergoing psyc...               3\n",
      "\n",
      "Cluster distribution:\n",
      "kmeans_cluster\n",
      "0     15\n",
      "1    243\n",
      "2    808\n",
      "3    889\n",
      "4     45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Apply Clustering Algorithms\n",
    "# 1. K-Means Clustering\n",
    "\n",
    "print(\"K-Means Clustering Results\")\n",
    "k = 5 # Set the desired number of clusters\n",
    "\n",
    "# Initialize and fit K-Means\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Assign the cluster labels\n",
    "df['kmeans_cluster'] = kmeans.labels_\n",
    "\n",
    "# Display the desired result\n",
    "kmeans_result = df[['cleaned_review', 'kmeans_cluster']]\n",
    "print(kmeans_result.head())\n",
    "print(f\"\\nCluster distribution:\\n{df['kmeans_cluster'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c6c54f8-430c-4605-9389-2d4a4d4f67ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical Clustering (Ward Linkage) Results\n",
      "                                      cleaned_review  agg_cluster_ward\n",
      "0  plot two teen couples go church party drink dr...                 0\n",
      "1  happy bastard 's quick movie review damn y2k b...                 0\n",
      "2  movies like make jaded movie viewer thankful i...                 0\n",
      "3  `` quest camelot `` warner bros first feature-...                 0\n",
      "4  synopsis mentally unstable man undergoing psyc...                 0\n",
      "\n",
      "Cluster distribution:\n",
      "agg_cluster_ward\n",
      "0    1645\n",
      "1     305\n",
      "2      17\n",
      "3      10\n",
      "4      23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Apply Clustering Algorithms\n",
    "# 2. Hierarchical Clustering- Ward Linkage\n",
    "\n",
    "print(\"Hierarchical Clustering (Ward Linkage) Results\")\n",
    "k = 5 # Set the desired number of clusters\n",
    "\n",
    "# Initialize and fit Agglomerative Clustering (Ward Linkage)\n",
    "agg_ward = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
    "\n",
    "# Fit and assign cluster labels\n",
    "df['agg_cluster_ward'] = agg_ward.fit_predict(X.toarray())\n",
    "\n",
    "# Display the desired result\n",
    "agg_ward_result = df[['cleaned_review', 'agg_cluster_ward']]\n",
    "print(agg_ward_result.head())\n",
    "print(f\"\\nCluster distribution:\\n{df['agg_cluster_ward'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "333928b9-8640-4af4-b260-2d153522f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical Clustering (Average Linkage) Results\n",
      "                                      cleaned_review  agg_cluster_average\n",
      "0  plot two teen couples go church party drink dr...                    0\n",
      "1  happy bastard 's quick movie review damn y2k b...                    0\n",
      "2  movies like make jaded movie viewer thankful i...                    0\n",
      "3  `` quest camelot `` warner bros first feature-...                    0\n",
      "4  synopsis mentally unstable man undergoing psyc...                    0\n",
      "\n",
      "Cluster distribution:\n",
      "agg_cluster_average\n",
      "0    1996\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Apply Clustering Algorithms\n",
    "# 2.1 Hierarchical Clustering- Average Linkage\n",
    "\n",
    "print(\"Hierarchical Clustering (Average Linkage) Results\")\n",
    "k = 5 # Set the desired number of clusters\n",
    "\n",
    "# Initialize and fit Agglomerative Clustering (Average Linkage)\n",
    "agg_average = AgglomerativeClustering(n_clusters=k, linkage='average')\n",
    "\n",
    "# Fit and assign cluster labels\n",
    "df['agg_cluster_average'] = agg_average.fit_predict(X.toarray())\n",
    "\n",
    "# Display the desired result\n",
    "agg_average_result = df[['cleaned_review', 'agg_cluster_average']]\n",
    "print(agg_average_result.head())\n",
    "print(f\"\\nCluster distribution:\\n{df['agg_cluster_average'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c394fa8-9202-4b25-a7d4-8f9effcfab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical Clustering (Complete Linkage) Results\n",
      "                                      cleaned_review  agg_cluster_complete\n",
      "0  plot two teen couples go church party drink dr...                     4\n",
      "1  happy bastard 's quick movie review damn y2k b...                     4\n",
      "2  movies like make jaded movie viewer thankful i...                     4\n",
      "3  `` quest camelot `` warner bros first feature-...                     1\n",
      "4  synopsis mentally unstable man undergoing psyc...                     4\n",
      "\n",
      "Cluster distribution:\n",
      "agg_cluster_complete\n",
      "0    812\n",
      "1    496\n",
      "2      1\n",
      "3     13\n",
      "4    678\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Apply Clustering Algorithms\n",
    "# 2.2 Hierarchical Clustering- Complete Linkage\n",
    "\n",
    "print(\"Hierarchical Clustering (Complete Linkage) Results\")\n",
    "k = 5 # Set the desired number of clusters\n",
    "\n",
    "# Initialize and fit Agglomerative Clustering (Complete Linkage)\n",
    "agg_complete = AgglomerativeClustering(n_clusters=k, linkage='complete')\n",
    "\n",
    "# Fit and assign cluster labels\n",
    "df['agg_cluster_complete'] = agg_complete.fit_predict(X.toarray())\n",
    "\n",
    "# Display the desired result\n",
    "agg_complete_result = df[['cleaned_review', 'agg_cluster_complete']]\n",
    "print(agg_complete_result.head())\n",
    "print(f\"\\nCluster distribution:\\n{df['agg_cluster_complete'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97f95378-cf6f-400e-a7c6-5dddc09e68a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Clustering Results\n",
      "                                      cleaned_review  dbscan_cluster\n",
      "0  plot two teen couples go church party drink dr...               0\n",
      "1  happy bastard 's quick movie review damn y2k b...               0\n",
      "2  movies like make jaded movie viewer thankful i...               0\n",
      "3  `` quest camelot `` warner bros first feature-...              -1\n",
      "4  synopsis mentally unstable man undergoing psyc...              -1\n",
      "\n",
      "Cluster distribution:\n",
      "dbscan_cluster\n",
      "-1      346\n",
      " 0     1513\n",
      " 1        4\n",
      " 2        5\n",
      " 3        5\n",
      " 4        3\n",
      " 5        4\n",
      " 6        5\n",
      " 7        3\n",
      " 8        5\n",
      " 9        8\n",
      " 10       3\n",
      " 11       4\n",
      " 12       6\n",
      " 13       7\n",
      " 14       6\n",
      " 15       3\n",
      " 16       4\n",
      " 17       3\n",
      " 18       3\n",
      " 19       6\n",
      " 20       4\n",
      " 21       4\n",
      " 22       3\n",
      " 23       5\n",
      " 24       4\n",
      " 25       3\n",
      " 26       3\n",
      " 27       3\n",
      " 28       6\n",
      " 29       3\n",
      " 30       3\n",
      " 31       3\n",
      " 32       6\n",
      " 33       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Apply Clustering Algorithms\n",
    "# 3. DBSCAN\n",
    "\n",
    "print(\"DBSCAN Clustering Results\")\n",
    "\n",
    "# Parameters\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=3, metric='cosine')\n",
    "\n",
    "# Fit and assign cluster labels\n",
    "df['dbscan_cluster'] = dbscan.fit_predict(X)\n",
    "\n",
    "# Display the desired result\n",
    "dbscan_result = df[['cleaned_review', 'dbscan_cluster']]\n",
    "print(dbscan_result.head())\n",
    "print(f\"\\nCluster distribution:\\n{df['dbscan_cluster'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f199bfe7-c411-4109-9dc2-256a3663ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compare the Clustering Results\n",
      "Scores are based on the cluster labels assigned in Step 4.\n",
      "KMeans -> Silhouette Score: 0.0065\n",
      "KMeans -> Calinski-Harabasz Index: 5.7\n",
      "\n",
      "\n",
      "Compare the Clustering Results\n",
      "Scores are based on the cluster labels assigned in Step 4.\n",
      "Hierarchical (Agglomerative) -> Silhouette Score: 0.0021\n",
      "Hierarchical (Agglomerative) -> Calinski-Harabasz Index: 6.1\n",
      "\n",
      "\n",
      "Compare the Clustering Results\n",
      "Scores are based on the cluster labels assigned in Step 4.\n",
      "DBSCAN -> Silhouette Score: -0.0031\n",
      "DBSCAN -> Calinski-Harabasz Index: 2.2\n",
      "\n",
      "\n",
      "Summary Interpretation\n",
      "Silhouette Score:Higher is better (range -1 to +1). Values near +1 indicate good, distinct clusters.\n",
      "Calinski-Harabasz Index:** Higher is better (no upper bound), indicating more distinct and dense clusters.\n"
     ]
    }
   ],
   "source": [
    "#Step 5 Evaluate and Compare Clusters\n",
    "\n",
    "def evaluate_clustering(X, labels, name):\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # For DBSCAN: ignore noise points (-1) when evaluating\n",
    "    mask = labels != -1\n",
    "    if mask.sum() == 0 or len(set(labels[mask])) < 2:\n",
    "        print(f\"{name}: not enough valid clusters for evaluation.\")\n",
    "        return\n",
    "\n",
    "    X_eval = X[mask]\n",
    "    labels_eval = labels[mask]\n",
    "\n",
    "    sil = silhouette_score(X_eval, labels_eval, metric='cosine')\n",
    "    ch  = calinski_harabasz_score(\n",
    "        X_eval.toarray() if hasattr(X_eval, \"toarray\") else X_eval,\n",
    "        labels_eval\n",
    "    )\n",
    "\n",
    "    print(\"\\nCompare the Clustering Results\")\n",
    "    print(\"Scores are based on the cluster labels assigned in Step 4.\")\n",
    "    print(f\"{name} -> Silhouette Score: {sil:.4f}\")\n",
    "    print(f\"{name} -> Calinski-Harabasz Index: {ch:.1f}\\n\")\n",
    "\n",
    "# Evaluate each algorithm\n",
    "evaluate_clustering(X, df['kmeans_cluster'], \"KMeans\")\n",
    "evaluate_clustering(X, df['agg_cluster_ward'], \"Hierarchical (Agglomerative)\")\n",
    "evaluate_clustering(X, df['dbscan_cluster'], \"DBSCAN\")\n",
    "\n",
    "print(\"\\nSummary Interpretation\")\n",
    "print(\"Silhouette Score:Higher is better (range -1 to +1). Values near +1 indicate good, distinct clusters.\")\n",
    "print(\"Calinski-Harabasz Index:** Higher is better (no upper bound), indicating more distinct and dense clusters.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
